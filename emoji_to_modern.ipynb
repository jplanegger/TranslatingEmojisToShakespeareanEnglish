{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:19:56.207246Z",
     "start_time": "2025-08-13T17:19:54.570323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_path = \"./emoji-modern\"\n",
    "model_name = \"google/byt5-base\"\n",
    "prompt = \"Interpret these emojis to an english sentence: \\n\""
   ],
   "id": "854b7d164773af08",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:40:29.267138Z",
     "start_time": "2025-08-13T16:38:02.864191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ],
   "id": "e899cde94b9d5488",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed4c25bae1e04495b1c28ab383102585"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\johan\\.cache\\huggingface\\hub\\models--google--byt5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/721 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d12b195d1184a4589e8e12e9acb2094"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91386042e4734a42bb78f4d539a5e0e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb1d844f090049488187872723d876c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40624763a4304868a599de5b7fe78311"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccdbbc9f22ed4764a1f87ab1c45e97e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:43:13.779671Z",
     "start_time": "2025-08-13T16:43:13.712591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_json(\"dataset.json\")\n",
    "\n",
    "df = df[df[\"modern\"].notna()][[\"emoji\", \"modern\"]]\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def add_prompt(example):\n",
    "    example[\"input\"] = f\"{prompt} {example['emoji']}\"\n",
    "    example[\"target\"] = example[\"modern\"]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(add_prompt)\n"
   ],
   "id": "e759faeab40cb0f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1414 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b3ef39b73864ff18aebc5e2b120f490"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:43:17.761640Z",
     "start_time": "2025-08-13T16:43:17.373917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(example):\n",
    "    model_inputs = tokenizer(example[\"input\"], truncation=True, padding=\"max_length\", max_length=196)\n",
    "    labels = tokenizer(example[\"target\"], truncation=True, padding=\"max_length\", max_length=196)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ],
   "id": "c91754a169480cf3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1414 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59634ac70c4743f682154a9ad0e7764d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:43:33.782050Z",
     "start_time": "2025-08-13T16:43:33.578612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                 # more rank → more capacity\n",
    "    lora_alpha=32,        # scale up to match r\n",
    "    target_modules=[\"q\", \"v\"],  # good for T5\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "ea05b7def7e17c63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,211,840 || all params: 583,865,088 || trainable%: 0.3788\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:12:00.159641Z",
     "start_time": "2025-08-13T16:43:35.606271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=30,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.merge_and_unload()\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ],
   "id": "1abda63e983c4f12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_14520\\3725205864.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 28:22, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>13.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.281200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.944800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.922200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.941400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.903400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.891400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.888700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.889600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.888300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.884600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.883100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.903700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./emoji-modern\\\\tokenizer_config.json',\n",
       " './emoji-modern\\\\special_tokens_map.json',\n",
       " './emoji-modern\\\\added_tokens.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:21:16.041950Z",
     "start_time": "2025-08-13T17:21:12.340180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path, device_map=None).to(device)\n",
    "model.eval()"
   ],
   "id": "88e15f7d5f60f6d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from ./emoji-modern led to missing keys in the model: encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(384, 1536)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-17): 17 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=384, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:48:55.085476Z",
     "start_time": "2025-08-13T17:48:41.563130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "few_shot = \"\"\"\n",
    "Example:\n",
    "😂🤣\n",
    "Modern: They laugh loudly together, delighting in mirth.\n",
    "\n",
    "Generate exactly a lines for the following emojis:\n",
    "Modern: [English]\n",
    "\"\"\"\n",
    "\n",
    "def generate_with_grounding(emoji, max_new_tokens=200, num_beams=5):\n",
    "    full_prompt = prompt # f\"{prompt} {few_shot} {emoji}\"\n",
    "    encoded = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **encoded,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            length_penalty=1.0\n",
    "        )\n",
    "    decoded = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    return decoded\n",
    "\n",
    "# Emoji input\n",
    "test_inputs = [\"😂🤣\", \"💔😭\", \"👑🙌\", \"😎🕶️\", \"🌊🐚💭💖\"]\n",
    "\n",
    "for sequence in test_inputs:\n",
    "    output = generate_with_grounding(emoji)\n",
    "    print(\"INPUT:\", sequence)\n",
    "    print(\"OUTPUT:\\n\", output)\n",
    "    print(\"—\" * 50)\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "ac967276f3414fa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: 😂🤣\n",
      "OUTPUT:\n",
      "  emojis to an english sentence: https://www.youtube.com/watch?v=_YouTubQQ__\n",
      "Now translate:\n",
      " 🌊🐚💖😴\n",
      "Modern: They laugh loudly, delighting in mirth.\n",
      "And now: Hello, there is\n",
      "\n",
      "——————————————————————————————————————————————————\n",
      "INPUT: 💔😭\n",
      "OUTPUT:\n",
      "  emojis to an english sentence: https://www.youtube.com/watch?v=_YouTubQQ__\n",
      "Now translate:\n",
      " 🌊🐚💖😴\n",
      "Modern: They laugh loudly, delighting in mirth.\n",
      "And now: Hello, there is\n",
      "\n",
      "——————————————————————————————————————————————————\n",
      "INPUT: 👑🙌\n",
      "OUTPUT:\n",
      "  emojis to an english sentence: https://www.youtube.com/watch?v=_YouTubQQ__\n",
      "Now translate:\n",
      " 🌊🐚💖😴\n",
      "Modern: They laugh loudly, delighting in mirth.\n",
      "And now: Hello, there is\n",
      "\n",
      "——————————————————————————————————————————————————\n",
      "INPUT: 😎🕶️\n",
      "OUTPUT:\n",
      "  emojis to an english sentence: https://www.youtube.com/watch?v=_YouTubQQ__\n",
      "Now translate:\n",
      " 🌊🐚💖😴\n",
      "Modern: They laugh loudly, delighting in mirth.\n",
      "And now: Hello, there is\n",
      "\n",
      "——————————————————————————————————————————————————\n",
      "INPUT: 🌊🐚💭💖\n",
      "OUTPUT:\n",
      "  emojis to an english sentence: https://www.youtube.com/watch?v=_YouTubQQ__\n",
      "Now translate:\n",
      " 🌊🐚💖😴\n",
      "Modern: They laugh loudly, delighting in mirth.\n",
      "And now: Hello, there is\n",
      "\n",
      "——————————————————————————————————————————————————\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T13:58:57.073077Z",
     "start_time": "2025-08-13T13:58:57.069397Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "9707500008b871e9",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
