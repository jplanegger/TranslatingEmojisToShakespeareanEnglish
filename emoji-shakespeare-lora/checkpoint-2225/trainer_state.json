{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 25.0,
  "eval_steps": 500,
  "global_step": 2225,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5649717514124294,
      "grad_norm": 0.3717050552368164,
      "learning_rate": 0.0009779775280898877,
      "loss": 11.2123,
      "step": 50
    },
    {
      "epoch": 1.1242937853107344,
      "grad_norm": 0.17734520137310028,
      "learning_rate": 0.0009555056179775281,
      "loss": 3.7878,
      "step": 100
    },
    {
      "epoch": 1.689265536723164,
      "grad_norm": 0.2193966954946518,
      "learning_rate": 0.0009330337078651686,
      "loss": 3.5818,
      "step": 150
    },
    {
      "epoch": 2.248587570621469,
      "grad_norm": 2.268176317214966,
      "learning_rate": 0.000910561797752809,
      "loss": 3.098,
      "step": 200
    },
    {
      "epoch": 2.8135593220338984,
      "grad_norm": 0.2114630788564682,
      "learning_rate": 0.0008880898876404495,
      "loss": 2.4219,
      "step": 250
    },
    {
      "epoch": 3.3728813559322033,
      "grad_norm": 0.22788961231708527,
      "learning_rate": 0.0008656179775280899,
      "loss": 2.2017,
      "step": 300
    },
    {
      "epoch": 3.937853107344633,
      "grad_norm": 0.30192142724990845,
      "learning_rate": 0.0008431460674157302,
      "loss": 2.138,
      "step": 350
    },
    {
      "epoch": 4.497175141242938,
      "grad_norm": 0.21319161355495453,
      "learning_rate": 0.0008206741573033708,
      "loss": 2.0513,
      "step": 400
    },
    {
      "epoch": 5.056497175141243,
      "grad_norm": 0.28773772716522217,
      "learning_rate": 0.0007982022471910112,
      "loss": 2.002,
      "step": 450
    },
    {
      "epoch": 5.621468926553672,
      "grad_norm": 0.2228350043296814,
      "learning_rate": 0.0007757303370786517,
      "loss": 1.9932,
      "step": 500
    },
    {
      "epoch": 6.1807909604519775,
      "grad_norm": 0.4164711833000183,
      "learning_rate": 0.0007532584269662921,
      "loss": 1.9656,
      "step": 550
    },
    {
      "epoch": 6.745762711864407,
      "grad_norm": 8.359803199768066,
      "learning_rate": 0.0007307865168539326,
      "loss": 1.9591,
      "step": 600
    },
    {
      "epoch": 7.305084745762712,
      "grad_norm": 1.1515806913375854,
      "learning_rate": 0.000708314606741573,
      "loss": 2.1219,
      "step": 650
    },
    {
      "epoch": 7.870056497175141,
      "grad_norm": 45.08720779418945,
      "learning_rate": 0.0006858426966292135,
      "loss": 1.9877,
      "step": 700
    },
    {
      "epoch": 8.429378531073446,
      "grad_norm": 0.32243087887763977,
      "learning_rate": 0.0006633707865168539,
      "loss": 1.9721,
      "step": 750
    },
    {
      "epoch": 8.994350282485875,
      "grad_norm": 2.386910915374756,
      "learning_rate": 0.0006408988764044944,
      "loss": 1.9945,
      "step": 800
    },
    {
      "epoch": 9.55367231638418,
      "grad_norm": 0.6239622831344604,
      "learning_rate": 0.0006184269662921348,
      "loss": 1.9473,
      "step": 850
    },
    {
      "epoch": 10.112994350282486,
      "grad_norm": 2.406656503677368,
      "learning_rate": 0.0005959550561797753,
      "loss": 1.9261,
      "step": 900
    },
    {
      "epoch": 10.677966101694915,
      "grad_norm": 3.2241568565368652,
      "learning_rate": 0.0005734831460674157,
      "loss": 1.9436,
      "step": 950
    },
    {
      "epoch": 11.23728813559322,
      "grad_norm": 0.5547454953193665,
      "learning_rate": 0.0005510112359550562,
      "loss": 1.9878,
      "step": 1000
    },
    {
      "epoch": 11.80225988700565,
      "grad_norm": 5.937144756317139,
      "learning_rate": 0.0005285393258426966,
      "loss": 1.9493,
      "step": 1050
    },
    {
      "epoch": 12.361581920903955,
      "grad_norm": 14.227012634277344,
      "learning_rate": 0.0005060674157303371,
      "loss": 1.968,
      "step": 1100
    },
    {
      "epoch": 12.926553672316384,
      "grad_norm": 1.1492459774017334,
      "learning_rate": 0.0004835955056179776,
      "loss": 1.9073,
      "step": 1150
    },
    {
      "epoch": 13.485875706214689,
      "grad_norm": 1.4259746074676514,
      "learning_rate": 0.000461123595505618,
      "loss": 1.8884,
      "step": 1200
    },
    {
      "epoch": 14.045197740112995,
      "grad_norm": 0.9764297604560852,
      "learning_rate": 0.00043865168539325845,
      "loss": 1.8712,
      "step": 1250
    },
    {
      "epoch": 14.610169491525424,
      "grad_norm": 2.1664812564849854,
      "learning_rate": 0.0004161797752808989,
      "loss": 1.8823,
      "step": 1300
    },
    {
      "epoch": 15.169491525423728,
      "grad_norm": 1.1045324802398682,
      "learning_rate": 0.0003937078651685393,
      "loss": 1.8651,
      "step": 1350
    },
    {
      "epoch": 15.734463276836157,
      "grad_norm": 1.4852702617645264,
      "learning_rate": 0.0003712359550561798,
      "loss": 1.8815,
      "step": 1400
    },
    {
      "epoch": 16.293785310734464,
      "grad_norm": 13.81637191772461,
      "learning_rate": 0.00034876404494382026,
      "loss": 1.8467,
      "step": 1450
    },
    {
      "epoch": 16.858757062146893,
      "grad_norm": 7.512419700622559,
      "learning_rate": 0.0003262921348314607,
      "loss": 1.8743,
      "step": 1500
    },
    {
      "epoch": 17.418079096045197,
      "grad_norm": 4.528231620788574,
      "learning_rate": 0.00030382022471910113,
      "loss": 1.8426,
      "step": 1550
    },
    {
      "epoch": 17.983050847457626,
      "grad_norm": 1.0172046422958374,
      "learning_rate": 0.0002813483146067416,
      "loss": 1.8653,
      "step": 1600
    },
    {
      "epoch": 18.54237288135593,
      "grad_norm": 2.638446807861328,
      "learning_rate": 0.00025887640449438206,
      "loss": 1.8337,
      "step": 1650
    },
    {
      "epoch": 19.10169491525424,
      "grad_norm": 1.6667101383209229,
      "learning_rate": 0.00023640449438202247,
      "loss": 1.8519,
      "step": 1700
    },
    {
      "epoch": 19.666666666666668,
      "grad_norm": 14.530111312866211,
      "learning_rate": 0.0002139325842696629,
      "loss": 1.856,
      "step": 1750
    },
    {
      "epoch": 20.225988700564972,
      "grad_norm": 3.6196837425231934,
      "learning_rate": 0.00019146067415730337,
      "loss": 1.8368,
      "step": 1800
    },
    {
      "epoch": 20.7909604519774,
      "grad_norm": 1.1393275260925293,
      "learning_rate": 0.0001689887640449438,
      "loss": 1.8489,
      "step": 1850
    },
    {
      "epoch": 21.350282485875706,
      "grad_norm": 3.7100462913513184,
      "learning_rate": 0.00014651685393258428,
      "loss": 1.8291,
      "step": 1900
    },
    {
      "epoch": 21.915254237288135,
      "grad_norm": 0.7872766852378845,
      "learning_rate": 0.0001240449438202247,
      "loss": 1.8542,
      "step": 1950
    },
    {
      "epoch": 22.47457627118644,
      "grad_norm": 0.8802235126495361,
      "learning_rate": 0.00010157303370786516,
      "loss": 1.8304,
      "step": 2000
    },
    {
      "epoch": 23.033898305084747,
      "grad_norm": 3.5035054683685303,
      "learning_rate": 7.910112359550562e-05,
      "loss": 1.8284,
      "step": 2050
    },
    {
      "epoch": 23.598870056497177,
      "grad_norm": 1.8506803512573242,
      "learning_rate": 5.6629213483146074e-05,
      "loss": 1.8474,
      "step": 2100
    },
    {
      "epoch": 24.15819209039548,
      "grad_norm": 2.0626511573791504,
      "learning_rate": 3.415730337078652e-05,
      "loss": 1.8251,
      "step": 2150
    },
    {
      "epoch": 24.72316384180791,
      "grad_norm": 1.1260350942611694,
      "learning_rate": 1.1685393258426966e-05,
      "loss": 1.8418,
      "step": 2200
    }
  ],
  "logging_steps": 50,
  "max_steps": 2225,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.42476540379136e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
