{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# In this file both trained models will translate first: Emoji to an english interpretation, Second: the emojis together with the english interpretation into a shakespearean english translation",
   "id": "f1db20d082186e04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T20:15:46.436180Z",
     "start_time": "2025-08-13T20:15:46.432068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "emoji_to_sha_model_path = \"./emoji-shakespeare-lora\"\n",
    "emoji_to_english_model_path = \"./emoji-modern\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Few-shot examples\n",
    "emoji_to_english_examples = [\n",
    "    (\"ğŸ±ğŸ“–\", \"The cat is reading a book.\"),\n",
    "    (\"ğŸğŸ\", \"An apple and another apple.\"),\n",
    "    (\"ğŸŒğŸ’”ğŸ˜¢ğŸŒˆ\", \"The sun is broken, I feel sad, but hope appears.\"),\n",
    "]\n",
    "\n",
    "english_to_sha_examples = [\n",
    "    (\"ğŸ±ğŸ“–\", \"The cat is reading a book.\", \"Behold the feline, engrossed in perusal of a tome.\"),\n",
    "    (\"ğŸğŸ\", \"An apple and another apple.\", \"A pome, and yet another pome, in mirthful harmony.\"),\n",
    "    (\"ğŸŒğŸ’”ğŸ˜¢ğŸŒˆ\", \"The sun is broken, I feel sad, but hope appears.\",\n",
    "     \"Lo, the sun is rent asunder, mine heart doth ache, yet hope doth shine forth as a radiant bow.\"),\n",
    "]"
   ],
   "id": "d527c6b24f9e2160",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T19:35:49.382713Z",
     "start_time": "2025-08-13T19:35:37.797400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "emoji2EnglishTokenizer = AutoTokenizer.from_pretrained(emoji_to_english_model_path)\n",
    "emoji2EnglishModel = AutoModelForSeq2SeqLM.from_pretrained(emoji_to_english_model_path).to(device)\n",
    "emoji2EnglishModel.eval()\n",
    "\n",
    "emoji2ShaTokenizer = AutoTokenizer.from_pretrained(emoji_to_sha_model_path)\n",
    "emoji2ShaModel = AutoModelForSeq2SeqLM.from_pretrained(emoji_to_sha_model_path).to(device)\n",
    "emoji2ShaModel.eval()"
   ],
   "id": "7a830312a5756355",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from ./emoji-modern led to missing keys in the model: encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "Loading adapter weights from ./emoji-shakespeare-lora led to missing keys in the model: encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.12.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.12.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.12.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.12.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.13.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.13.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.13.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.13.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.14.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.14.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.14.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.14.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.15.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.15.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.15.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.15.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.16.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.16.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.16.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.16.layer.0.SelfAttention.v.lora_B.default.weight, encoder.block.17.layer.0.SelfAttention.q.lora_A.default.weight, encoder.block.17.layer.0.SelfAttention.q.lora_B.default.weight, encoder.block.17.layer.0.SelfAttention.v.lora_A.default.weight, encoder.block.17.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight, decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight, decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight, decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight, decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight, decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight, decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight, decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight, decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(384, 1536)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-17): 17 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): Linear(in_features=1536, out_features=768, bias=False)\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): Linear(in_features=768, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=3968, bias=False)\n",
       "              (wo): Linear(in_features=3968, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=384, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T20:15:39.745017Z",
     "start_time": "2025-08-13T20:15:39.738961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def emoji_to_english(emoji_seq):\n",
    "    prompt = \"Translate emoji to an english sentence:\\n\"\n",
    "    for e, eng in emoji_to_english_examples:\n",
    "        prompt += f\"Emoji: {e}\\nModern English: {eng}\\n\\n\"\n",
    "    prompt += f\"Emoji: {emoji_seq}\\nModern English:\"\n",
    "\n",
    "    inputs = emoji2EnglishTokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = emoji2EnglishModel.generate(**inputs, max_length=inputs['input_ids'].shape[1]+50)\n",
    "    text = emoji2EnglishTokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return text.split(\"Modern English:\")[-1].strip()\n",
    "\n",
    "def english_to_shakespeare(emoji_seq, english_text):\n",
    "    prompt = \"Translate the following into a Shakespearean English sentence, using both the emoji and Modern English as reference:\\n\"\n",
    "    for e, eng, sha in english_to_sha_examples:\n",
    "        prompt += f\"Emoji: {e}\\nModern English: {eng}\\nShakespearean: {sha}\\n\\n\"\n",
    "    prompt += f\"Emoji: {emoji_seq}\\nModern English: {english_text}\\nShakespearean:\"\n",
    "\n",
    "    inputs = emoji2ShaTokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = emoji2ShaModel.generate(**inputs, max_length=inputs['input_ids'].shape[1]+100)\n",
    "    text = emoji2ShaTokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return text.split(\"Shakespearean:\")[-1].strip()\n",
    "\n",
    "def emoji_to_shakespeare(emoji_seq):\n",
    "    english_translation = emoji_to_english(emoji_seq)\n",
    "    shakespeare_translation = english_to_shakespeare(emoji_seq, english_translation)\n",
    "    return shakespeare_translation\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ],
   "id": "dc26a23ed62906e7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T20:18:35.857486Z",
     "start_time": "2025-08-13T20:18:35.601943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_json(\"dataset.json\")\n",
    "dataset = Dataset.from_pandas(df)\n"
   ],
   "id": "75a563773dba1016",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T20:27:00.143474Z",
     "start_time": "2025-08-13T20:22:09.635191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "sample_data = dataset.shuffle(seed=42).select(range(70))\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "preds = []\n",
    "refs = []\n",
    "\n",
    "for entry in sample_data:\n",
    "    shakespeare = emoji_to_shakespeare(entry[\"emoji\"])\n",
    "    preds.append(shakespeare)\n",
    "    refs.append([entry[\"shakespeare\"]])\n",
    "\n",
    "# Compute BLEU\n",
    "bleu_result = bleu_metric.compute(predictions=preds, references=refs)\n",
    "print(f\"BLEU score: {bleu_result['score']:.2f}\")\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_result = rouge_metric.compute(predictions=preds, references=[r[0] for r in refs])\n",
    "print(\"ROUGE scores:\")\n",
    "for k, v in rouge_result.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "# Print sample results\n",
    "print(\"\\nSample predictions vs references:\")\n",
    "for emoji, pred, ref in zip([d[\"emoji\"] for d in sample_data], preds, [r[0] for r in refs]):\n",
    "    print(f\"Emoji: {emoji}\")\n",
    "    print(f\"Pred : {pred}\")\n",
    "    print(f\"Ref  : {ref}\")\n",
    "    print(\"â€”\" * 50)\n"
   ],
   "id": "bd3182636e1ea6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.26\n",
      "ROUGE scores:\n",
      "  rouge1: 0.0721\n",
      "  rouge2: 0.0006\n",
      "  rougeL: 0.0709\n",
      "  rougeLsum: 0.0714\n",
      "\n",
      "Sample predictions vs references:\n",
      "Emoji: ğŸ“šâœï¸ğŸ“ğŸ“ğŸ˜´ğŸ’¤\n",
      "Pred : A cat and I\n",
      "Shake, I\n",
      "Ref  : Though wisdom's crown awaits, these weary eyes grow heavy o'er my learned tomes and slumber calls.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸï¸ğŸ˜¤â˜•ğŸ¥ğŸš¢\n",
      "Pred : I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so so so so so so so so\n",
      "Ref  : Upon a deserted isle, a scorned soul doth seethe, seeking solace in a cup of bitter brew, whilst dreaming of fluffy breakfast banquet aboard a noble vessel.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒ¸ğŸâ˜€ï¸ğŸ˜Š\n",
      "Pred : sentence is a shakespearean translation of the sentence and the emoji is a shakespearean translation.\n",
      "The sentence is a shakespearean translation and the emoji is a shakespearean e.\n",
      "S. \"\n",
      "Ref  : Sweet workers dance 'round blooms whilst Phoebus smiles, and all my heart rejoices!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸš«ğŸ‘…ğŸˆ\n",
      "Pred : Lo, the sun is broken, I (\n",
      "Si, (\n",
      "S\n",
      "S\n",
      "Ref  : 'Nay, taste not the fig, and lo, beware the mouth.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒ·ğŸ’ŒğŸ˜Š\n",
      "Pred : A pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, ano\n",
      "Ref  : Thy tender words do make my spirit bloom like tulips in the morning sun.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜´ğŸ¤ğŸš«ğŸ‘¤\n",
      "Pred : A pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome,\n",
      "Ref  : After a long day, a gentleman refrains from engaging in societal gatherings, favoring quiet slumber.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¥ğŸ¨ğŸ¥’ğŸ¥ğŸ˜¢\n",
      "Pred : sentence translation is a simple translation of emojis and modern emojis.\n",
      "Emoji: ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸ\n",
      "M//////\n",
      "S//////\n",
      "Ref  : Methinks I find myself in a melancholy state, bereft of croissant, ice cream, cucumber, and tangy, sun-kissed yellow fruit.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ“šğŸ“ğŸ˜©â°\n",
      "Pred : A pome, and another\n",
      "S, i, ,\n",
      "Ref  : These books and quills do burden my poor soul whilst Time's swift chariot races toward my doom!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ ğŸ˜«ğŸ˜•\n",
      "Pred : A pome.\n",
      "S. A.\n",
      "Ref  : Upon the carousel of existence, weariness and discontent doth grip mine heart.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ’ªğŸºğŸ¦·ğŸ¥\n",
      "Pred : The cat and cat.\n",
      "S\n",
      "Ref  : In sooth, a man of strength, in noble tavern, doth quaff ale and partake in the morn's repast.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¤©â˜•\n",
      "Pred : A pome\n",
      "Emoji: ğŸ¤©\n",
      "S\n",
      "Ref  : ğŸ¤©â˜•.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¤—ğŸ˜¥ğŸ¥ªğŸ¦…ğŸ˜œ\n",
      "Pred : The cat\n",
      "S\n",
      "S\n",
      "Ref  : The caring soul, despite his tears, joyfully consumes a sandwich whilst admiring the bird's cheeky antics.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸš´â€â™‚ï¸ğŸŒ³\n",
      "Pred : A pome, and another pome,  s\n",
      "Ref  : Through leafy glades I ride with windâ€™s soft breath as guide.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒ®ğŸ”¥ğŸ˜­\n",
      "Pred : A pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, ano\n",
      "Ref  : Alack! This fiery morsel doth burn mine tongue and bring forth tears of torment!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ›©ï¸ğŸï¸\n",
      "Pred : The cat\n",
      "S, I, II\n",
      "S,\n",
      "Ref  : Through azure air I wing my course to palm-ringâ€™d shore.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜«ğŸ˜™ğŸ¥¬\n",
      "Pred : sentence in Shakespearean English translation is a simple translation of Shakespearean English. The sentence is a simple translation of Shakespearean English and Modern.\n",
      "# # # # # #\n",
      "Ref  : I struggle in a world of salads, yet my heart's affection lies there.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ§¡ğŸ™‚ğŸ¤§\n",
      "Pred : A pome, and yet a\n",
      "Ref  : A pensive heart smiles through a vexing nose.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜‹ğŸ¸ğŸ¤©ğŸ¤ğŸ¯ğŸ’“\n",
      "Pred : A pome, and yet ano\n",
      "Ref  : Methinks a most jubilant leap from the jolly frog hath captured mine heart, as I place my hopes upon the sturdy stones of yon cottage.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¤­ğŸ˜ªğŸ¤§ğŸ§ğŸ†ğŸ¥˜\n",
      "Pred : I\n",
      "Ref  : A weary soul, besieged by malaise, seeketh respite in a sea of succulent fare.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: âš“ğŸ¥—ğŸµ\n",
      "Pred : A pome, and another pome,\n",
      "Ref  : Sail to the island to find the talking monkey.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¡ğŸ˜‹\n",
      "Pred : A pome\n",
      "Shake (\n",
      "S)\n",
      "S)\n",
      "Ref  : The delightful sweetness of a warm, melting mochi doth bring joy to the heart.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¥‚ğŸ¦ŠğŸ‘¥ğŸ¦ğŸ’—\n",
      "Pred : A\n",
      "Ref  : One might proclaim a jubilant libation, as a vulpine cohort gathers, whilst avians take flight, all hearts alight with merriment.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ­ğŸ‘âœ…ğŸ‘ŠğŸ’ğŸ±\n",
      "Pred : A pome, I\n",
      "S,\n",
      "Ref  : A sweet delight shared with open hands, a hearty embrace of cherries, all wrapped in a paper of secrets.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ­ğŸ’”ğŸ˜¢\n",
      "Pred : A\n",
      "Ref  : Alas, our love doth play upon fate's stage, where tears are writ in sorrow's script.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ§ğŸ•ï¸ğŸŸï¸ğŸ«¦\n",
      "Pred : sentence translation is a simple translation of emojis and modern emojis.\n",
      "Emoji: ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸ\n",
      "M/M/Y/Y/Y//\n",
      "S/M/Y/Y/Y//\n",
      "Ref  : Upon yonder snowy retreat, there lies a grand arena, where iced confections are crafted with delight.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸƒâ€â™‚ï¸ğŸƒâ€â™€ï¸ğŸ˜ ğŸ’¢ğŸ\n",
      "Pred : The cat\n",
      "S\n",
      "S\n",
      "Ref  : Others fly past whilst bitter defeat doth poison my racing heart!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ“šğŸ“â°ğŸ˜©ğŸ’Šâ˜•\n",
      "Pred : A pome, and another pome,\n",
      "Ref  : These books and quills do burden my poor soul whilst Time's cruel hand doth press and potions aid!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜ğŸ‚ğŸ’–ğŸ¥­ğŸ»ğŸ¤œ\n",
      "Pred : sentence is a shakespearean translation of the Shakespearean English sentence. The shakespearean English sentence is a shakespearean translation of the Shakespearean English and Moder:\n",
      "Ref  : Oh, how merry the occasion of mine birthday doth bring forth joy, as the sweet kiss of love doth embrace the peppery touch of the wild boar.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒ‹ğŸ˜¡\n",
      "Pred : A pome\n",
      "Shake (\n",
      "S)\n",
      "S)\n",
      "Ref  : Like Vesuvius my rage doth burst with molten wrath!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¦‰ğŸ’\n",
      "Pred : A pome\n",
      "EmojÃ­: ğŸ±\n",
      "Ref  : The owl cherishes the cherry.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒŠâ›µğŸ¤ğŸŒŸ\n",
      "Pred : A pome, and another pome,\n",
      "Ref  : Through life's great ocean we do sail, with friendship as our star.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒŸğŸ’ğŸ‘‘\n",
      "Pred : A pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome,\n",
      "Ref  : Thou art a jewel rare, a noble friend more precious than a crown.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ“šğŸ“ğŸ˜¡â°ğŸ’¢\n",
      "Pred : A pome, and another\n",
      "S, i,\n",
      "Ref  : These cursed tomes and quills do vex me whilst Time's cruel hand doth press!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒŸğŸ—¡ï¸ğŸ¦\n",
      "Pred : I feel\n",
      "Ref  : A lion bright with starlight crowned, my sword for honor drawn.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ“šğŸ¤“\n",
      "Pred : A pome\n",
      "EmojÃ­:\n",
      "Ref  : In learned pursuits do I find my truest joy!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸˆğŸ²ğŸ¤’ğŸ˜’\n",
      "Pred : A\n",
      "Ref  : The fruit plucked from fair orchard, stewed with spices, brings forth a malady most vile, causing mine own countenance to bear a visage most sour.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸªğŸ \n",
      "Pred : A\n",
      "Ref  : What merry spectacle doth fill mine eyes with wonder!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¸ğŸ¥‘ğŸ¥•\n",
      "Pred : The cat\n",
      "Ref  : At the feast, I partook of an aperitif; methinks a celery root beside me with an olive doth make merry the meal.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ½ğŸ˜µğŸ˜´\n",
      "Pred : A pome\n",
      "Emoji: ğŸ±\n",
      "S\n",
      "Ref  : As thou beholdest a lonely kitten in a state of confusion, its eyes drooping with fatigue.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¨ğŸ–Œï¸ğŸ­ğŸ›ï¸ğŸ–¼ï¸ğŸŒŸ\n",
      "Pred : A pome, and yet ano\n",
      "Ref  : Within these hallowed halls where muses dwell, such treasures feast mine eyes with beauty fit for gods!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¸ğŸµğŸ”ŠğŸ¤˜\n",
      "Pred : A pome, and yet ano\n",
      "Ref  : My strings do cry with thunder's mighty voice, and I am king of all the world!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜ğŸ˜‡ğŸ«£ğŸ«ğŸ«•ğŸ¤“\n",
      "Pred : I love the way I wake\n",
      "Translate the following into a Shakespearean English sentence into a Shakespearean English sentence:\n",
      "The cat is reading\n",
      "Shake, I\n",
      "Ref  : A merry jest hath rendered my countenance serene, whilst the youths, with their heads bowed, in meditation, their brows furrowed, didst ponder deeply.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: âš ï¸ğŸ˜ƒğŸŒğŸ˜¢\n",
      "Pred : A pome, and another pome,\n",
      "Ref  : Beware, cheer for this delightful banana, yet be wary of its sorrowful destiny.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ’›ğŸ¦…ğŸ«€ğŸğŸ¦µğŸ‘‡\n",
      "Pred : A cat and a\n",
      "Sh i\n",
      "S\n",
      "Ref  : The golden eagle, with its sharp talons, delves into the bread, casting a gaze upon the kneeling.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ’»ğŸ˜¡ğŸ”¨\n",
      "Pred : A pome, and another pome,  s\n",
      "Ref  : This vile machine doth rouse such wrath I'd crush it with mine hammer!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜‚ğŸ¤£\n",
      "Pred : A pome\n",
      "Emoji: ((()\n",
      "S//////\n",
      "Ref  : Such mirth doth shake my very ribs whilst tears of joy do flow!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ‘€ğŸ¥§ğŸ«’ğŸ¸ğŸ±\n",
      "Pred : I f\n",
      "S\n",
      "S\n",
      "Ref  : I doth gaze upon the cherry pie, quaffing wine within the chilled chalice.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ“±ğŸ’¢ğŸ”¥\n",
      "Pred : A pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome,\n",
      "Ref  : This cursed glass doth vex me sore and set my very soul ablaze!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸŒ‹ğŸŒ§ï¸ğŸ”¥ğŸ’¨\n",
      "Pred : sentence is a short sentence translated into a Shakespearean English sentence. The sentence is a short sentence translated into a Shakespearean English sentence.\n",
      "Shakespearean Engl\n",
      "Ref  : The mountain weeps with tears of fire, while ash-winds howl and moan.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¯ğŸğŸ˜™ğŸ«ğŸ¦‰ğŸ¥\n",
      "Pred : A pome, and another pome,\n",
      "Ref  : In a castle, a sleepy child, with a kiss upon the cheeks, opens a window, where an owl hoots, greeting a chirping lamb.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ›ï¸ğŸ’³ğŸ’¸ğŸ˜…\n",
      "Pred : sentence translation is a simple translation of emojis and modern emojis.\n",
      "Emoji: ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸ\n",
      "M/M/Y/Y/Y//\n",
      "Shakespearean\n",
      "Ref  : Though my purse grows light with spending, yet mirth doth bubble up at my folly!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¸ğŸ˜ªğŸ‘ğŸ¥­ğŸ’š\n",
      "Pred : A cat and a cat.\n",
      "# # I should # u\n",
      "# # I #\n",
      "Ref  : The slumberous frog, with a hand outstretched for an apple, doth wear a heart of emerald.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ•ğŸ¥¤\n",
      "Pred : A\n",
      "Ref  : With bread and cheese so fair I sup, with draught to cheer my soul.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜¢ğŸ¤ğŸ‘ğŸ§\n",
      "Pred : A pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome, a pome,\n",
      "Ref  : In sorrow I find solace, for the beloved's gaze doth open mine eyes wide with wonder.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¦·ğŸ˜­ğŸ¤«\n",
      "Pred : The cat\n",
      "S\n",
      "S\n",
      "Ref  : Mine tooth doth protest with grief, yet I keep mine sorrow hidden.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ«‘ğŸ¤ğŸ§ğŸ™ğŸ¥•\n",
      "Pred : I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so sorry that I am so so so so so so so so\n",
      "Ref  : Verily, a gentle lamb doth gaze upon the humble carrot, seeking blessings.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜¡ğŸ¤“\n",
      "Pred : A pome\n",
      "EmojÃ­: ğŸ¤“\n",
      "Ref  : Alas, a ruffled brow doth reflect the mental toil encountered during scholarly pursuits.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¤ªğŸ­\n",
      "Pred : A\n",
      "Ref  : Like mad court jester do I play with wit most wild and strange!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜‡ğŸ§ğŸ˜œ\n",
      "Pred : A pome, and another\n",
      "S, i, ,\n",
      "Ref  : Thou art a benevolent dreamer, a curious spirit, and in a jestful mood.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ­ğŸ¤\n",
      "Pred : A \"A\n",
      "Shake, \"A\n",
      "Ref  : Sweet and dark, a confection's hue.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ’ğŸ¤¯ğŸ˜¯ğŸŒ‹ğŸ·\n",
      "Pred : A po\n",
      "Ref  : Oh, what a surprise! The world's end is nigh, yet let us raise a toast to the fiery depths.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¥—ğŸ—»ğŸ¤£ğŸğŸ‹ğŸœ\n",
      "Pred : A pome, and another pome,  a\n",
      "Ref  : Upon the verdant hill, a jestful soul, with bread by their side, doth enjoy a bowlful of citrus broth.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸš€ğŸª\n",
      "Pred : A pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, another pome, ano\n",
      "Ref  : Through starry seas I sail in craft of manâ€™s own forging.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¨ğŸ–¼ï¸\n",
      "Pred : I feel sad, but hope appears.\n",
      "Shake, I (\n",
      "Ref  : Mine brush doth paint what beauty fills my soul!\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ¦¶ğŸ¥’ğŸ¤ŒğŸ˜œ\n",
      "Pred : The cat\n",
      "S\n",
      "S\n",
      "Ref  : Mine ears, akin to the gentle pepper, do jest in merriment.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜ªğŸ¥Ÿ\n",
      "Pred : A pome\n",
      "Emoji: ((()\n",
      "S//////\n",
      "Ref  : In a state of slumber, he doth partake in a feast.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ…ğŸ¥­ğŸ«£ğŸ§ƒğŸ˜«ğŸ¯\n",
      "Pred : A pome, and yet another pome, in mirthful harmony.\n",
      "Translate the following into a Shakespearean English sentence:\n",
      "Emoji: ğŸ\n",
      "Modern English: A pome,\n",
      "Ref  : The weary traveler, having faced an onslaught of relentless challenges, now longs for the comfort and solace of a humble meal shared in the tranquil confines of a castle's keep.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ˜¡ğŸ¤“\n",
      "Pred : A pome\n",
      "EmojÃ­: ğŸ¤“\n",
      "Ref  : Thou art furious with thy learned wit!.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ™ŒğŸ™ğŸ§ ğŸ¥¦ğŸ¤­ğŸ˜\n",
      "Pred : A pome, and another pome,\n",
      "Ref  : God bless thee, for thy wisdom exceeds that of the learned sage, as thou dost approach the verdant plains of knowledge with joyous mirth.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Emoji: ğŸ§¹ğŸª£\n",
      "Pred : A pome, and another pome, in mirthful harmony.\n",
      "The emoji is also used to translate the following sentence into a Shakespearean English sentence:\n",
      "1. A.,\n",
      "Ref  : With broom and pail I banish dust from mine own halls.\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
